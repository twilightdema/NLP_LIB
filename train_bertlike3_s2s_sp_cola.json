{
  "model": {
    "class": "SequenceTransferLearningWrapper",
    "config": {
      "output_class_num": 2,
      "encoder_checkpoint": null,
      "train_encoder": true,
      "max_input_length": 256,
      "drop_out": 0.1,
      "cached_data_dir": "_cache_",

      "encoder_model": {
        "class": "BERTWrapper",
        "config": {
          "len_limit": 256,
          "d_model": 512,
          "d_inner_hid": 2048,
          "n_head": 4,
          "d_k": 512,
          "d_v": 512,
          "layers": 3,
          "dropout": 0.1,
          "share_word_emb": true,
          "max_input_length": 256,
          "max_mask_tokens": 80,
          "cached_data_dir": "_cache_"    
        }
      },

      "encoder_dict_dataset": {
        "class": "ColaBalancedDatasetWrapper",
        "config": {
          "base_data_dir": "_tmp_"
        }
      }
    
    }
  },
  "dataset": {
    "class": "ColaBalancedDatasetWrapper",
    "config": {
      "base_data_dir": "_tmp_"
    }
  },
  "input_transform": {
    "class": "BERTSentencePiecePretrainWrapper",
    "config": {
      "column_id": 0,
      "max_dict_size" : 150,
      "max_seq_length" : 256,
      "is_input": true,
      "is_pretrain": false,
      "clf_id": 2
    }
  },  
  "output_transform": {
    "class": "SingleClassTransformWrapper",
    "config": {
      "column_id": 1
    }
  },
  "callbacks": [
  ],
  "execution": {
    "config": {
      "optimizer": "bert",
      "optimizer_params": [0.00005, 0.9, 0.997, 1e-9, 1000, 1.0, 0.01],
      "batch_size": 32,
      "epochs": 60,
      "watch_metric": "val_acc",
      "output_dir": "_outputs_/bertlike3_s2s_sp_cola",
      "save_weight_history": false,
      "resume_if_possible": true
    }
  }
}
